# ============================================
# LLM PROVIDER SELECTION
# ============================================
# Options: azure, huggingface
# Default: huggingface (due to Azure quota limits)
LLM_PROVIDER=huggingface

# Options: azure, local
# Default: local (due to Azure quota limits)
EMBEDDING_PROVIDER=local

# ============================================
# AZURE OPENAI CONFIGURATION
# ============================================
# Azure OpenAI API credentials
AZURE_OPENAI_API_KEY=your_azure_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Azure OpenAI Deployments
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# ============================================
# HUGGING FACE CONFIGURATION
# ============================================
# Hugging Face API token (get from https://huggingface.co/settings/tokens)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Hugging Face model for LLM
# Recommended options (2025):
# - mistralai/Mistral-Nemo-Instruct-v1 (12B, successor to 7B series)
# - mistralai/Mistral-Small-24B-Instruct-2504 (Latest high-performance)
# - meta-llama/Llama-3.2-3B-Instruct (Fast, reliable, popular)
# - Qwen/Qwen2.5-7B-Instruct (Top-performing 7B)
HUGGINGFACE_MODEL=mistralai/Mistral-Nemo-Instruct-v1

# ============================================
# RAG CONFIGURATION (Optional)
# ============================================
# Number of document chunks to retrieve
TOP_K=3

# Chunk size in tokens
CHUNK_SIZE=400

# Overlap between chunks in tokens
CHUNK_OVERLAP=50

# Maximum conversation history messages to keep
MAX_HISTORY_MESSAGES=10
